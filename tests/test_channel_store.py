"""ChannelStore ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""

import json

import pytest

from seosoyoung.memory.channel_store import ChannelStore


@pytest.fixture
def store(tmp_path):
    return ChannelStore(base_dir=tmp_path)


class TestChannelBuffer:
    """ì±„ë„ ë£¨íŠ¸ ë©”ì‹œì§€ ë²„í¼ í…ŒìŠ¤íŠ¸"""

    def test_append_and_load_channel_message(self, store):
        msg = {"ts": "1234.5678", "user": "U001", "text": "ì•ˆë…•í•˜ì„¸ìš”"}
        store.append_channel_message("C001", msg)

        loaded = store.load_channel_buffer("C001")
        assert len(loaded) == 1
        assert loaded[0]["text"] == "ì•ˆë…•í•˜ì„¸ìš”"

    def test_append_accumulates(self, store):
        store.append_channel_message("C001", {"ts": "1", "user": "U001", "text": "ì²« ë²ˆì§¸"})
        store.append_channel_message("C001", {"ts": "2", "user": "U002", "text": "ë‘ ë²ˆì§¸"})

        loaded = store.load_channel_buffer("C001")
        assert len(loaded) == 2

    def test_load_empty_buffer(self, store):
        assert store.load_channel_buffer("NONEXISTENT") == []

    def test_preserves_unicode(self, store):
        msg = {"ts": "1", "user": "U001", "text": "ì´ëª¨ì§€ í…ŒìŠ¤íŠ¸ ğŸ”¥"}
        store.append_channel_message("C001", msg)
        loaded = store.load_channel_buffer("C001")
        assert loaded[0]["text"] == "ì´ëª¨ì§€ í…ŒìŠ¤íŠ¸ ğŸ”¥"

    def test_independent_per_channel(self, store):
        store.append_channel_message("C001", {"ts": "1", "user": "U001", "text": "A"})
        store.append_channel_message("C002", {"ts": "2", "user": "U002", "text": "B"})

        assert store.load_channel_buffer("C001")[0]["text"] == "A"
        assert store.load_channel_buffer("C002")[0]["text"] == "B"


class TestThreadBuffer:
    """ìŠ¤ë ˆë“œ ë©”ì‹œì§€ ë²„í¼ í…ŒìŠ¤íŠ¸"""

    def test_append_and_load_thread_message(self, store):
        msg = {"ts": "1234.9999", "user": "U001", "text": "ìŠ¤ë ˆë“œ ë©”ì‹œì§€", "thread_ts": "1234.5678"}
        store.append_thread_message("C001", "1234.5678", msg)

        loaded = store.load_thread_buffer("C001", "1234.5678")
        assert len(loaded) == 1
        assert loaded[0]["text"] == "ìŠ¤ë ˆë“œ ë©”ì‹œì§€"

    def test_thread_accumulates(self, store):
        store.append_thread_message("C001", "1234.5678", {"ts": "1", "user": "U001", "text": "ì²«ì§¸"})
        store.append_thread_message("C001", "1234.5678", {"ts": "2", "user": "U002", "text": "ë‘˜ì§¸"})

        loaded = store.load_thread_buffer("C001", "1234.5678")
        assert len(loaded) == 2

    def test_load_empty_thread_buffer(self, store):
        assert store.load_thread_buffer("C001", "NONEXISTENT") == []

    def test_independent_per_thread(self, store):
        store.append_thread_message("C001", "ts_a", {"ts": "1", "user": "U001", "text": "A"})
        store.append_thread_message("C001", "ts_b", {"ts": "2", "user": "U002", "text": "B"})

        assert store.load_thread_buffer("C001", "ts_a")[0]["text"] == "A"
        assert store.load_thread_buffer("C001", "ts_b")[0]["text"] == "B"

    def test_load_all_thread_buffers(self, store):
        store.append_thread_message("C001", "ts_a", {"ts": "1", "user": "U001", "text": "A1"})
        store.append_thread_message("C001", "ts_a", {"ts": "2", "user": "U001", "text": "A2"})
        store.append_thread_message("C001", "ts_b", {"ts": "3", "user": "U002", "text": "B1"})

        all_threads = store.load_all_thread_buffers("C001")
        assert "ts_a" in all_threads
        assert "ts_b" in all_threads
        assert len(all_threads["ts_a"]) == 2
        assert len(all_threads["ts_b"]) == 1

    def test_load_all_thread_buffers_empty(self, store):
        assert store.load_all_thread_buffers("NONEXISTENT") == {}


class TestTokenCounting:
    """í† í° ì¹´ìš´íŒ… í…ŒìŠ¤íŠ¸"""

    def test_count_buffer_tokens_empty(self, store):
        assert store.count_buffer_tokens("NONEXISTENT") == 0

    def test_count_buffer_tokens_with_data(self, store):
        store.append_channel_message("C001", {"ts": "1", "user": "U001", "text": "ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤."})
        store.append_thread_message("C001", "ts_a", {"ts": "2", "user": "U001", "text": "ìŠ¤ë ˆë“œ ë©”ì‹œì§€ì…ë‹ˆë‹¤."})

        token_count = store.count_buffer_tokens("C001")
        assert token_count > 0

    def test_count_includes_channel_and_threads(self, store):
        store.append_channel_message("C001", {"ts": "1", "user": "U001", "text": "ì±„ë„ ë©”ì‹œì§€"})
        channel_only = store.count_buffer_tokens("C001")

        store.append_thread_message("C001", "ts_a", {"ts": "2", "user": "U001", "text": "ìŠ¤ë ˆë“œ ë©”ì‹œì§€"})
        with_thread = store.count_buffer_tokens("C001")

        assert with_thread > channel_only


class TestClearBuffers:
    """ë²„í¼ ë¹„ìš°ê¸° í…ŒìŠ¤íŠ¸"""

    def test_clear_buffers(self, store):
        store.append_channel_message("C001", {"ts": "1", "user": "U001", "text": "ì±„ë„"})
        store.append_thread_message("C001", "ts_a", {"ts": "2", "user": "U001", "text": "ìŠ¤ë ˆë“œ"})

        store.clear_buffers("C001")

        assert store.load_channel_buffer("C001") == []
        assert store.load_thread_buffer("C001", "ts_a") == []
        assert store.count_buffer_tokens("C001") == 0

    def test_clear_nonexistent_buffers(self, store):
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì±„ë„ ë²„í¼ ë¹„ìš°ê¸°ë„ ì—ëŸ¬ ì—†ìŒ"""
        store.clear_buffers("NONEXISTENT")


class TestDigest:
    """digest.md CRUD í…ŒìŠ¤íŠ¸"""

    def test_get_digest_empty(self, store):
        assert store.get_digest("NONEXISTENT") is None

    def test_save_and_get_digest(self, store):
        content = "## ì±„ë„ ê´€ì°° ìš”ì•½\n\n- ì˜¤ëŠ˜ì€ ì¡°ìš©í•œ í•˜ë£¨ì˜€ë‹¤."
        meta = {"last_digested_at": "2026-02-11T10:00:00Z", "total_digests": 1}
        store.save_digest("C001", content, meta)

        result = store.get_digest("C001")
        assert result is not None
        assert result["content"] == content
        assert result["meta"]["total_digests"] == 1

    def test_save_digest_overwrites(self, store):
        store.save_digest("C001", "ì²« ë²ˆì§¸ ìš”ì•½", {"total_digests": 1})
        store.save_digest("C001", "ë‘ ë²ˆì§¸ ìš”ì•½", {"total_digests": 2})

        result = store.get_digest("C001")
        assert result["content"] == "ë‘ ë²ˆì§¸ ìš”ì•½"
        assert result["meta"]["total_digests"] == 2

    def test_digest_preserves_unicode(self, store):
        content = "ğŸ”¥ ì±„ë„ì—ì„œ ì—´ë¤ í† ë¡ ì´ ë²Œì–´ì¡Œë‹¤"
        store.save_digest("C001", content, {})

        result = store.get_digest("C001")
        assert result["content"] == content

    def test_digest_independent_per_channel(self, store):
        store.save_digest("C001", "ì±„ë„1 ìš”ì•½", {})
        store.save_digest("C002", "ì±„ë„2 ìš”ì•½", {})

        assert store.get_digest("C001")["content"] == "ì±„ë„1 ìš”ì•½"
        assert store.get_digest("C002")["content"] == "ì±„ë„2 ìš”ì•½"

    def test_creates_directory(self, tmp_path):
        deep_path = tmp_path / "a" / "b" / "c"
        store = ChannelStore(base_dir=deep_path)
        store.save_digest("C001", "test", {})
        assert store.get_digest("C001")["content"] == "test"
