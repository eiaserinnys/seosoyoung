"""JSON ê¸°ë°˜ ì €ì¥ì†Œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

.md â†’ .json ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜, JSON í•­ëª© ë°°ì—´ CRUD,
ì•„ì¹´ì´ë¸Œ ìƒì„±, ì¼ê´„ ë§ˆì´ê·¸ë ˆì´ì…˜ ëª¨ë“ˆì„ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import json
from datetime import datetime, timezone
from pathlib import Path

import pytest

from seosoyoung.slackbot.memory.store import (
    MemoryRecord,
    MemoryStore,
    generate_ltm_id,
    generate_obs_id,
    parse_md_observations,
    parse_md_persistent,
)


# â”€â”€ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _make_obs_items(items_data, session_date="2026-02-10"):
    result = []
    for i, (priority, content) in enumerate(items_data):
        result.append({
            "id": f"obs_{session_date.replace('-', '')}_{i:03d}",
            "priority": priority,
            "content": content,
            "session_date": session_date,
            "created_at": f"{session_date}T00:00:00+00:00",
            "source": "observer",
        })
    return result


def _make_ltm_items(items_data):
    result = []
    for i, (priority, content) in enumerate(items_data):
        result.append({
            "id": f"ltm_20260210_{i:03d}",
            "priority": priority,
            "content": content,
            "promoted_at": "2026-02-10T00:00:00+00:00",
        })
    return result


@pytest.fixture
def store(tmp_path):
    return MemoryStore(base_dir=tmp_path)


# â”€â”€ ID ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class TestGenerateObsId:
    def test_first_id_for_date(self):
        obs_id = generate_obs_id([], "2026-02-10")
        assert obs_id == "obs_20260210_000"

    def test_sequential_ids(self):
        existing = [{"id": "obs_20260210_000"}, {"id": "obs_20260210_001"}]
        obs_id = generate_obs_id(existing, "2026-02-10")
        assert obs_id == "obs_20260210_002"

    def test_different_date_resets_seq(self):
        existing = [{"id": "obs_20260210_005"}]
        obs_id = generate_obs_id(existing, "2026-02-11")
        assert obs_id == "obs_20260211_000"

    def test_defaults_to_today(self):
        obs_id = generate_obs_id([])
        today = datetime.now(timezone.utc).strftime("%Y%m%d")
        assert obs_id.startswith(f"obs_{today}_")


class TestGenerateLtmId:
    def test_first_id(self):
        ltm_id = generate_ltm_id([], "2026-02-10")
        assert ltm_id == "ltm_20260210_000"

    def test_sequential_ids(self):
        existing = [{"id": "ltm_20260210_000"}]
        ltm_id = generate_ltm_id(existing, "2026-02-10")
        assert ltm_id == "ltm_20260210_001"


# â”€â”€ .md íŒŒì‹± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class TestParseMdObservations:
    def test_basic_parsing(self):
        md = (
            "## [2026-02-10] Session\n"
            "ğŸ”´ Critical finding\n"
            "ğŸŸ¡ Medium note\n"
            "ğŸŸ¢ Low priority\n"
        )
        items = parse_md_observations(md)
        assert len(items) == 3
        assert items[0]["priority"] == "ğŸ”´"
        assert items[0]["content"] == "Critical finding"
        assert items[0]["session_date"] == "2026-02-10"
        assert items[0]["source"] == "migrated"
        assert items[0]["id"] == "obs_20260210_000"

    def test_strips_priority_labels(self):
        """HIGH/MEDIUM/LOW ë ˆì´ë¸”ì´ ì œê±°ë¨"""
        md = (
            "## [2026-02-10] Session\n"
            "ğŸ”´ HIGH - ì¤‘ìš”í•œ ë°œê²¬\n"
            "ğŸŸ¡ MEDIUM â€” ë³´í†µ ë©”ëª¨\n"
            "ğŸŸ¢ LOW ë‚®ì€ ìš°ì„ ìˆœìœ„\n"
        )
        items = parse_md_observations(md)
        assert items[0]["content"] == "ì¤‘ìš”í•œ ë°œê²¬"
        assert items[1]["content"] == "ë³´í†µ ë©”ëª¨"
        assert items[2]["content"] == "ë‚®ì€ ìš°ì„ ìˆœìœ„"

    def test_multiple_dates(self):
        md = (
            "## [2026-02-09] Day 1\n"
            "ğŸ”´ Day1 obs\n\n"
            "## [2026-02-10] Day 2\n"
            "ğŸŸ¡ Day2 obs\n"
        )
        items = parse_md_observations(md)
        assert len(items) == 2
        assert items[0]["session_date"] == "2026-02-09"
        assert items[1]["session_date"] == "2026-02-10"

    def test_empty_input(self):
        assert parse_md_observations("") == []
        assert parse_md_observations("  ") == []
        assert parse_md_observations(None) == []

    def test_no_emoji_lines_skipped(self):
        md = "## [2026-02-10] Session\nê·¸ëƒ¥ í…ìŠ¤íŠ¸\nğŸ”´ ì§„ì§œ í•­ëª©\n"
        items = parse_md_observations(md)
        assert len(items) == 1
        assert items[0]["content"] == "ì§„ì§œ í•­ëª©"


class TestParseMdPersistent:
    def test_basic_parsing(self):
        md = "ğŸ”´ ì¥ê¸° ê¸°ì–µ 1\nğŸŸ¡ ì¥ê¸° ê¸°ì–µ 2\n"
        items = parse_md_persistent(md)
        assert len(items) == 2
        assert items[0]["priority"] == "ğŸ”´"
        assert items[0]["content"] == "ì¥ê¸° ê¸°ì–µ 1"
        assert items[0]["id"] == "ltm_20260223_000"  # ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ë°˜
        assert "promoted_at" in items[0]

    def test_plain_text_becomes_medium(self):
        """ì´ëª¨ì§€ ì—†ëŠ” ì¤„ì€ ğŸŸ¡ ìš°ì„ ìˆœìœ„ë¡œ ë³€í™˜"""
        md = "ì¼ë°˜ í…ìŠ¤íŠ¸ ë©”ëª¨\n"
        items = parse_md_persistent(md)
        assert len(items) == 1
        assert items[0]["priority"] == "ğŸŸ¡"

    def test_skips_headers_and_hr(self):
        md = "# Header\n---\nğŸ”´ ì§„ì§œ í•­ëª©\n"
        items = parse_md_persistent(md)
        assert len(items) == 1
        assert items[0]["content"] == "ì§„ì§œ í•­ëª©"

    def test_empty_input(self):
        assert parse_md_persistent("") == []
        assert parse_md_persistent(None) == []


# â”€â”€ .md â†’ .json ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class TestAutoMigrationObservations:
    """store.get_record() í˜¸ì¶œ ì‹œ .md â†’ .json ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜"""

    def test_md_to_json_migration_on_get(self, store):
        """get_record ì‹œ .mdë§Œ ì¡´ì¬í•˜ë©´ ìë™ìœ¼ë¡œ .json ë³€í™˜"""
        thread_ts = "1234567890.123456"
        store._ensure_dirs()

        # ë©”íƒ€ë°ì´í„° ì§ì ‘ ìƒì„±
        meta = {
            "thread_ts": thread_ts,
            "user_id": "U12345",
            "username": "test_user",
            "observation_tokens": 50,
            "last_observed_at": None,
            "total_sessions_observed": 1,
            "reflection_count": 0,
            "created_at": "2026-02-10T00:00:00+00:00",
        }
        store._meta_path(thread_ts).write_text(
            json.dumps(meta, ensure_ascii=False), encoding="utf-8"
        )

        # ë ˆê±°ì‹œ .md íŒŒì¼ ìƒì„±
        md_content = (
            "## [2026-02-10] Session Observations\n"
            "ğŸ”´ ì‚¬ìš©ìëŠ” ì»¤ë°‹ ë©”ì‹œì§€ë¥¼ í•œê¸€ë¡œ ì‘ì„±\n"
            "ğŸŸ¡ íŠ¸ë ë¡œ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë¨¼ì € í™•ì¸\n"
        )
        store._obs_md_path(thread_ts).write_text(md_content, encoding="utf-8")

        # get_record í˜¸ì¶œ â†’ ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜
        record = store.get_record(thread_ts)

        assert record is not None
        assert len(record.observations) == 2
        assert record.observations[0]["priority"] == "ğŸ”´"
        assert record.observations[0]["content"] == "ì‚¬ìš©ìëŠ” ì»¤ë°‹ ë©”ì‹œì§€ë¥¼ í•œê¸€ë¡œ ì‘ì„±"
        assert record.observations[0]["source"] == "migrated"
        assert record.observations[0]["id"].startswith("obs_20260210_")

        # .jsonì´ ìƒì„±ë˜ê³  .mdëŠ” ì‚­ì œë¨
        assert store._obs_path(thread_ts).exists()
        assert not store._obs_md_path(thread_ts).exists()

        # ìƒì„±ëœ .jsonì˜ ë‚´ìš© ê²€ì¦
        json_items = json.loads(
            store._obs_path(thread_ts).read_text(encoding="utf-8")
        )
        assert len(json_items) == 2

    def test_json_takes_priority_over_md(self, store):
        """.jsonê³¼ .md ëª¨ë‘ ì¡´ì¬í•˜ë©´ .json ìš°ì„ """
        thread_ts = "1234567890.999"
        store._ensure_dirs()

        meta = {"thread_ts": thread_ts}
        store._meta_path(thread_ts).write_text(
            json.dumps(meta), encoding="utf-8"
        )

        json_items = _make_obs_items([("ğŸ”´", "JSON í•­ëª©")])
        store._obs_path(thread_ts).write_text(
            json.dumps(json_items, ensure_ascii=False), encoding="utf-8"
        )

        md_content = "## [2026-02-10] Session\nğŸŸ¡ MD í•­ëª© (ë¬´ì‹œë¨)\n"
        store._obs_md_path(thread_ts).write_text(md_content, encoding="utf-8")

        record = store.get_record(thread_ts)
        assert len(record.observations) == 1
        assert record.observations[0]["content"] == "JSON í•­ëª©"
        # .mdëŠ” ê·¸ëŒ€ë¡œ ë‚¨ì•„ ìˆìŒ (ì‚­ì œí•˜ì§€ ì•ŠìŒ)
        assert store._obs_md_path(thread_ts).exists()

    def test_no_md_no_json_empty_observations(self, store):
        """ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ ê´€ì°° ë¦¬ìŠ¤íŠ¸"""
        thread_ts = "empty_ts"
        store._ensure_dirs()

        meta = {"thread_ts": thread_ts}
        store._meta_path(thread_ts).write_text(
            json.dumps(meta), encoding="utf-8"
        )

        record = store.get_record(thread_ts)
        assert record is not None
        assert record.observations == []


class TestAutoMigrationPersistent:
    """store.get_persistent() í˜¸ì¶œ ì‹œ .md â†’ .json ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜"""

    def test_md_to_json_migration_on_get(self, store):
        """get_persistent ì‹œ .mdë§Œ ì¡´ì¬í•˜ë©´ ìë™ ë³€í™˜"""
        store._ensure_dirs()

        md_content = "ğŸ”´ ì¥ê¸° ê¸°ì–µ 1\nğŸŸ¡ ì¥ê¸° ê¸°ì–µ 2\n"
        store._persistent_md_path().write_text(md_content, encoding="utf-8")

        result = store.get_persistent()

        assert result is not None
        items = result["content"]
        assert len(items) == 2
        assert items[0]["priority"] == "ğŸ”´"
        assert items[0]["content"] == "ì¥ê¸° ê¸°ì–µ 1"
        assert items[0]["id"].startswith("ltm_")

        # .jsonì´ ìƒì„±ë˜ê³  .mdëŠ” ì‚­ì œë¨
        assert store._persistent_content_path().exists()
        assert not store._persistent_md_path().exists()

    def test_json_takes_priority_over_md(self, store):
        """.jsonê³¼ .md ëª¨ë‘ ì¡´ì¬í•˜ë©´ .json ìš°ì„ """
        store._ensure_dirs()

        json_items = _make_ltm_items([("ğŸ”´", "JSON ì¥ê¸° ê¸°ì–µ")])
        store._persistent_content_path().write_text(
            json.dumps(json_items, ensure_ascii=False), encoding="utf-8"
        )

        store._persistent_md_path().write_text(
            "ğŸŸ¡ MD ê¸°ì–µ (ë¬´ì‹œë¨)\n", encoding="utf-8"
        )

        result = store.get_persistent()
        assert len(result["content"]) == 1
        assert result["content"][0]["content"] == "JSON ì¥ê¸° ê¸°ì–µ"


class TestAutoMigrationNewObservations:
    """store.get_new_observations() í˜¸ì¶œ ì‹œ .md â†’ .json ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜"""

    def test_md_to_json_migration(self, store):
        """ë ˆê±°ì‹œ .new.mdê°€ ìˆìœ¼ë©´ íŒŒì‹± í›„ ì‚­ì œ"""
        store._ensure_dirs()
        thread_ts = "new_obs_ts"

        md_content = "## [2026-02-10] Session\nğŸ”´ ìƒˆ ê´€ì°°\n"
        store._new_obs_md_path(thread_ts).write_text(md_content, encoding="utf-8")

        items = store.get_new_observations(thread_ts)
        assert len(items) == 1
        assert items[0]["content"] == "ìƒˆ ê´€ì°°"

        # .mdëŠ” ì‚­ì œë¨
        assert not store._new_obs_md_path(thread_ts).exists()

    def test_json_takes_priority(self, store):
        """.new.jsonì´ ìˆìœ¼ë©´ .new.md ë¬´ì‹œ"""
        store._ensure_dirs()
        thread_ts = "new_obs_ts2"

        json_items = _make_obs_items([("ğŸ”´", "JSON ìƒˆ ê´€ì°°")])
        store._new_obs_path(thread_ts).write_text(
            json.dumps(json_items, ensure_ascii=False), encoding="utf-8"
        )
        store._new_obs_md_path(thread_ts).write_text(
            "ğŸŸ¡ MD ìƒˆ ê´€ì°° (ë¬´ì‹œë¨)\n", encoding="utf-8"
        )

        items = store.get_new_observations(thread_ts)
        assert len(items) == 1
        assert items[0]["content"] == "JSON ìƒˆ ê´€ì°°"


# â”€â”€ JSON í•­ëª© ë°°ì—´ CRUD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class TestSaveAndGetJsonItems:
    """save_record / get_recordì˜ JSON í•­ëª© ë°°ì—´ ì €ì¥Â·ë¡œë“œ"""

    def test_roundtrip_observation_items(self, store):
        """ê´€ì°° í•­ëª© ë¦¬ìŠ¤íŠ¸ê°€ ì •í™•íˆ ì§ë ¬í™”/ì—­ì§ë ¬í™”ë¨"""
        items = _make_obs_items([
            ("ğŸ”´", "ì²« ë²ˆì§¸ ê´€ì°°"),
            ("ğŸŸ¡", "ë‘ ë²ˆì§¸ ê´€ì°°"),
            ("ğŸŸ¢", "ì„¸ ë²ˆì§¸ ê´€ì°°"),
        ])
        record = MemoryRecord(
            thread_ts="ts_crud_001",
            user_id="U123",
            observations=items,
            observation_tokens=100,
        )

        store.save_record(record)
        loaded = store.get_record("ts_crud_001")

        assert loaded is not None
        assert len(loaded.observations) == 3
        for orig, loaded_item in zip(items, loaded.observations):
            assert orig["id"] == loaded_item["id"]
            assert orig["priority"] == loaded_item["priority"]
            assert orig["content"] == loaded_item["content"]
            assert orig["session_date"] == loaded_item["session_date"]
            assert orig["source"] == loaded_item["source"]

    def test_observations_stored_as_json_array(self, store):
        """.json íŒŒì¼ì´ ì‹¤ì œë¡œ JSON ë°°ì—´ì¸ì§€ í™•ì¸"""
        items = _make_obs_items([("ğŸ”´", "í…ŒìŠ¤íŠ¸")])
        record = MemoryRecord(thread_ts="ts_format", observations=items)
        store.save_record(record)

        raw = json.loads(
            store._obs_path("ts_format").read_text(encoding="utf-8")
        )
        assert isinstance(raw, list)
        assert len(raw) == 1
        assert raw[0]["id"] == items[0]["id"]


class TestSaveAndGetPersistentJson:
    """save_persistent / get_persistentì˜ JSON í•­ëª© ë°°ì—´ ì €ì¥Â·ë¡œë“œ"""

    def test_roundtrip_persistent_items(self, store):
        items = _make_ltm_items([
            ("ğŸ”´", "ì¥ê¸° ê¸°ì–µ A"),
            ("ğŸŸ¡", "ì¥ê¸° ê¸°ì–µ B"),
        ])
        meta = {"last_promoted_at": "2026-02-10T00:00:00Z", "total_promotions": 5}

        store.save_persistent(items, meta)
        result = store.get_persistent()

        assert result is not None
        assert result["content"] == items
        assert result["meta"]["total_promotions"] == 5

    def test_persistent_stored_as_json_array(self, store):
        """.json íŒŒì¼ì´ ì‹¤ì œë¡œ JSON ë°°ì—´ì¸ì§€ í™•ì¸"""
        items = _make_ltm_items([("ğŸ”´", "í…ŒìŠ¤íŠ¸")])
        store.save_persistent(items, {})

        raw = json.loads(
            store._persistent_content_path().read_text(encoding="utf-8")
        )
        assert isinstance(raw, list)
        assert len(raw) == 1


class TestNewObservationsJson:
    """save_new_observations / get_new_observationsì˜ JSON í•­ëª© ë°°ì—´"""

    def test_roundtrip(self, store):
        items = _make_obs_items([("ğŸ”´", "ì´ë²ˆ í„´ ìƒˆ ê´€ì°°")])
        store.save_new_observations("ts_new", items)

        loaded = store.get_new_observations("ts_new")
        assert len(loaded) == 1
        assert loaded[0]["content"] == "ì´ë²ˆ í„´ ìƒˆ ê´€ì°°"

    def test_empty_when_not_exists(self, store):
        assert store.get_new_observations("NONEXISTENT") == []

    def test_clear(self, store):
        items = _make_obs_items([("ğŸ”´", "ì‚­ì œë  ê´€ì°°")])
        store.save_new_observations("ts_clear", items)
        store.clear_new_observations("ts_clear")
        assert store.get_new_observations("ts_clear") == []


class TestArchivePersistentJson:
    """archive_persistentê°€ .json ì•„ì¹´ì´ë¸Œë¥¼ ìƒì„±í•˜ëŠ”ì§€ í™•ì¸"""

    def test_archive_creates_json_file(self, store):
        items = _make_ltm_items([("ğŸ”´", "ì•„ì¹´ì´ë¸Œ ëŒ€ìƒ ê¸°ì–µ")])
        store.save_persistent(items, {})

        archive_path = store.archive_persistent()
        assert archive_path is not None
        assert archive_path.suffix == ".json"
        assert archive_path.parent.name == "archive"

        archived = json.loads(archive_path.read_text(encoding="utf-8"))
        assert isinstance(archived, list)
        assert archived[0]["content"] == "ì•„ì¹´ì´ë¸Œ ëŒ€ìƒ ê¸°ì–µ"

    def test_archive_preserves_original(self, store):
        items = _make_ltm_items([("ğŸ”´", "ì›ë³¸")])
        store.save_persistent(items, {"key": "value"})
        store.archive_persistent()

        result = store.get_persistent()
        assert result is not None
        assert result["content"][0]["content"] == "ì›ë³¸"


# â”€â”€ ì¼ê´„ ë§ˆì´ê·¸ë ˆì´ì…˜ ëª¨ë“ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class TestMigrateMemoryDir:
    """migrate_memory_dir ì¼ê´„ ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸"""

    def test_migrate_observations(self, tmp_path):
        from seosoyoung.slackbot.memory.migration import migrate_memory_dir

        obs_dir = tmp_path / "observations"
        obs_dir.mkdir()

        (obs_dir / "ts_001.md").write_text(
            "## [2026-02-10] Session\nğŸ”´ ê´€ì°° 1\nğŸŸ¡ ê´€ì°° 2\n",
            encoding="utf-8",
        )
        (obs_dir / "ts_002.md").write_text(
            "## [2026-02-11] Session\nğŸŸ¢ ê´€ì°° 3\n",
            encoding="utf-8",
        )
        # .meta.jsonë„ ìƒì„± (get_recordì™€ ë¬´ê´€í•˜ê²Œ migration.pyëŠ” .mdë§Œ ì²˜ë¦¬)

        report = migrate_memory_dir(tmp_path)

        assert report.total_converted == 2
        assert len(report.observations_converted) == 2
        assert report.errors == []

        # .json ìƒì„± í™•ì¸
        assert (obs_dir / "ts_001.json").exists()
        assert (obs_dir / "ts_002.json").exists()

        # .md ì‚­ì œ, .md.bak ìƒì„± í™•ì¸
        assert not (obs_dir / "ts_001.md").exists()
        assert (obs_dir / "ts_001.md.bak").exists()

        # JSON ë‚´ìš© ê²€ì¦
        items = json.loads(
            (obs_dir / "ts_001.json").read_text(encoding="utf-8")
        )
        assert len(items) == 2
        assert items[0]["content"] == "ê´€ì°° 1"

    def test_migrate_persistent(self, tmp_path):
        from seosoyoung.slackbot.memory.migration import migrate_memory_dir

        persistent_dir = tmp_path / "persistent"
        persistent_dir.mkdir()

        (persistent_dir / "recent.md").write_text(
            "ğŸ”´ ì¥ê¸° ê¸°ì–µ 1\nğŸŸ¡ ì¥ê¸° ê¸°ì–µ 2\n",
            encoding="utf-8",
        )

        report = migrate_memory_dir(tmp_path)

        assert report.persistent_converted is True
        assert (persistent_dir / "recent.json").exists()
        assert not (persistent_dir / "recent.md").exists()
        assert (persistent_dir / "recent.md.bak").exists()

        items = json.loads(
            (persistent_dir / "recent.json").read_text(encoding="utf-8")
        )
        assert len(items) == 2

    def test_dry_run_no_changes(self, tmp_path):
        from seosoyoung.slackbot.memory.migration import migrate_memory_dir

        obs_dir = tmp_path / "observations"
        obs_dir.mkdir()
        (obs_dir / "ts_001.md").write_text(
            "## [2026-02-10] Session\nğŸ”´ ê´€ì°°\n", encoding="utf-8"
        )

        report = migrate_memory_dir(tmp_path, dry_run=True)

        assert report.dry_run is True
        assert len(report.observations_converted) == 1
        # ì‹¤ì œ íŒŒì¼ì€ ë³€ê²½ë˜ì§€ ì•ŠìŒ
        assert (obs_dir / "ts_001.md").exists()
        assert not (obs_dir / "ts_001.json").exists()
        assert not (obs_dir / "ts_001.md.bak").exists()

    def test_skip_when_json_exists(self, tmp_path):
        from seosoyoung.slackbot.memory.migration import migrate_memory_dir

        obs_dir = tmp_path / "observations"
        obs_dir.mkdir()
        (obs_dir / "ts_001.md").write_text("ğŸ”´ MD content\n", encoding="utf-8")
        (obs_dir / "ts_001.json").write_text("[]", encoding="utf-8")

        report = migrate_memory_dir(tmp_path)

        assert len(report.observations_converted) == 0
        assert len(report.skipped) == 1

    def test_empty_directory(self, tmp_path):
        from seosoyoung.slackbot.memory.migration import migrate_memory_dir

        report = migrate_memory_dir(tmp_path)
        assert report.total_converted == 0
        assert report.errors == []

    def test_nonexistent_directory(self, tmp_path):
        from seosoyoung.slackbot.memory.migration import migrate_memory_dir

        report = migrate_memory_dir(tmp_path / "nonexistent")
        assert report.total_converted == 0
        assert len(report.errors) == 1


class TestMigrationCli:
    """scripts/migrate_om_to_json.py CLI í…ŒìŠ¤íŠ¸"""

    def test_cli_dry_run(self, tmp_path):
        import subprocess

        obs_dir = tmp_path / "observations"
        obs_dir.mkdir()
        (obs_dir / "ts_001.md").write_text(
            "## [2026-02-10] Session\nğŸ”´ CLI í…ŒìŠ¤íŠ¸\n", encoding="utf-8"
        )

        script = Path(__file__).resolve().parent.parent.parent / "scripts" / "migrate_om_to_json.py"
        result = subprocess.run(
            ["python", str(script), "--base-dir", str(tmp_path), "--dry-run"],
            capture_output=True,
            text=True,
            encoding="utf-8",
        )

        assert result.returncode == 0
        assert "DRY RUN" in result.stdout
        # ì‹¤ì œ íŒŒì¼ ë³€ê²½ ì—†ìŒ
        assert (obs_dir / "ts_001.md").exists()
        assert not (obs_dir / "ts_001.json").exists()

    def test_cli_actual_migration(self, tmp_path):
        import subprocess

        obs_dir = tmp_path / "observations"
        obs_dir.mkdir()
        (obs_dir / "ts_001.md").write_text(
            "## [2026-02-10] Session\nğŸ”´ ì‹¤ì œ ë³€í™˜\n", encoding="utf-8"
        )

        script = Path(__file__).resolve().parent.parent.parent / "scripts" / "migrate_om_to_json.py"
        result = subprocess.run(
            ["python", str(script), "--base-dir", str(tmp_path)],
            capture_output=True,
            text=True,
            encoding="utf-8",
        )

        assert result.returncode == 0
        assert "ê´€ì°° ë¡œê·¸ ë³€í™˜: 1ê±´" in result.stdout
        assert (obs_dir / "ts_001.json").exists()

    def test_cli_nonexistent_dir(self):
        import subprocess

        script = Path(__file__).resolve().parent.parent.parent / "scripts" / "migrate_om_to_json.py"
        result = subprocess.run(
            ["python", str(script), "--base-dir", "/nonexistent/path"],
            capture_output=True,
            text=True,
            encoding="utf-8",
        )

        assert result.returncode == 1
