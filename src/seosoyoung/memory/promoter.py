"""Promoter / Compactor ëª¨ë“ˆ

ì¥ê¸° ê¸°ì–µ í›„ë³´ë¥¼ ê²€í† í•˜ì—¬ ìŠ¹ê²©(Promoter)í•˜ê³ ,
ì¥ê¸° ê¸°ì–µì´ ì„ê³„ì¹˜ë¥¼ ë„˜ìœ¼ë©´ ì••ì¶•(Compactor)í•©ë‹ˆë‹¤.
"""

import logging
import re
from dataclasses import dataclass

import openai

from seosoyoung.memory.prompts import build_compactor_prompt, build_promoter_prompt
from seosoyoung.memory.token_counter import TokenCounter

logger = logging.getLogger(__name__)


@dataclass
class PromoterResult:
    """Promoter ì¶œë ¥ ê²°ê³¼"""

    promoted: str = ""
    rejected: str = ""
    promoted_count: int = 0
    rejected_count: int = 0
    priority_counts: dict = None

    def __post_init__(self):
        if self.priority_counts is None:
            self.priority_counts = {}


@dataclass
class CompactorResult:
    """Compactor ì¶œë ¥ ê²°ê³¼"""

    compacted: str = ""
    token_count: int = 0


def _extract_tag(text: str, tag_name: str) -> str:
    """XML íƒœê·¸ ë‚´ìš©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´."""
    pattern = rf"<{tag_name}>(.*?)</{tag_name}>"
    match = re.search(pattern, text, re.DOTALL)
    if match:
        return match.group(1).strip()
    return ""


def _count_entries(text: str) -> int:
    """ì´ëª¨ì§€ í”„ë¦¬í”½ìŠ¤(ğŸ”´ğŸŸ¡ğŸŸ¢) ë˜ëŠ” '-' ë¡œ ì‹œì‘í•˜ëŠ” ë¹„ì–´ìˆì§€ ì•Šì€ ì¤„ ìˆ˜ë¥¼ ì¹´ìš´íŠ¸."""
    if not text or not text.strip():
        return 0
    count = 0
    for line in text.strip().split("\n"):
        line = line.strip()
        if not line:
            continue
        if line[0] in ("ğŸ”´", "ğŸŸ¡", "ğŸŸ¢", "-", "â€¢"):
            count += 1
        elif len(line) > 1:
            count += 1
    return count


def _count_priority(text: str) -> dict:
    """ìŠ¹ê²© í…ìŠ¤íŠ¸ì—ì„œ ìš°ì„ ìˆœìœ„ë³„ ì¹´ìš´íŠ¸ë¥¼ ì¶”ì¶œ."""
    counts = {}
    if not text:
        return counts
    for line in text.strip().split("\n"):
        line = line.strip()
        if not line:
            continue
        for emoji in ("ğŸ”´", "ğŸŸ¡", "ğŸŸ¢"):
            if line.startswith(emoji):
                counts[emoji] = counts.get(emoji, 0) + 1
                break
    return counts


def parse_promoter_output(text: str) -> PromoterResult:
    """Promoter ì‘ë‹µì—ì„œ <promoted>ì™€ <rejected> íƒœê·¸ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    promoted = _extract_tag(text, "promoted")
    rejected = _extract_tag(text, "rejected")

    return PromoterResult(
        promoted=promoted,
        rejected=rejected,
        promoted_count=_count_entries(promoted),
        rejected_count=_count_entries(rejected),
        priority_counts=_count_priority(promoted),
    )


def parse_compactor_output(text: str) -> str:
    """Compactor ì‘ë‹µì—ì„œ <compacted> íƒœê·¸ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    compacted = _extract_tag(text, "compacted")
    return compacted if compacted else text.strip()


class Promoter:
    """ì¥ê¸° ê¸°ì–µ í›„ë³´ë¥¼ ê²€í† í•˜ì—¬ ìŠ¹ê²©"""

    def __init__(self, api_key: str, model: str = "gpt-5.2"):
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.model = model

    async def promote(
        self,
        candidates: list[dict],
        existing_persistent: str,
    ) -> PromoterResult:
        """í›„ë³´ í•­ëª©ë“¤ì„ ê²€í† í•˜ì—¬ ì¥ê¸° ê¸°ì–µ ìŠ¹ê²© ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            candidates: í›„ë³´ í•­ëª© ë¦¬ìŠ¤íŠ¸ [{"ts": ..., "priority": ..., "content": ...}]
            existing_persistent: ê¸°ì¡´ ì¥ê¸° ê¸°ì–µ í…ìŠ¤íŠ¸

        Returns:
            PromoterResult
        """
        candidate_text = self._format_candidates(candidates)
        prompt = build_promoter_prompt(existing_persistent, candidate_text)

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            max_completion_tokens=8_000,
        )

        result_text = response.choices[0].message.content or ""
        return parse_promoter_output(result_text)

    @staticmethod
    def _format_candidates(candidates: list[dict]) -> str:
        """í›„ë³´ í•­ëª©ì„ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§¤íŒ…."""
        lines = []
        for entry in candidates:
            priority = entry.get("priority", "ğŸŸ¢")
            content = entry.get("content", "")
            ts = entry.get("ts", "")
            lines.append(f"{priority} [{ts}] {content}")
        return "\n".join(lines)

    @staticmethod
    def merge_promoted(existing: str, promoted: str) -> str:
        """ìŠ¹ê²©ëœ í•­ëª©ì„ ê¸°ì¡´ ì¥ê¸° ê¸°ì–µì— ë¨¸ì§€í•©ë‹ˆë‹¤."""
        if not existing or not existing.strip():
            return promoted
        if not promoted or not promoted.strip():
            return existing
        return f"{existing}\n\n{promoted}"


class Compactor:
    """ì¥ê¸° ê¸°ì–µì„ ì••ì¶•"""

    def __init__(self, api_key: str, model: str = "gpt-5.2"):
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.model = model
        self.token_counter = TokenCounter()

    async def compact(
        self,
        persistent: str,
        target_tokens: int,
    ) -> CompactorResult:
        """ì¥ê¸° ê¸°ì–µì„ ì••ì¶•í•©ë‹ˆë‹¤.

        Args:
            persistent: í˜„ì¬ ì¥ê¸° ê¸°ì–µ í…ìŠ¤íŠ¸
            target_tokens: ëª©í‘œ í† í° ìˆ˜

        Returns:
            CompactorResult
        """
        prompt = build_compactor_prompt(persistent, target_tokens)

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            max_completion_tokens=16_000,
        )

        result_text = response.choices[0].message.content or ""
        compacted = parse_compactor_output(result_text)
        token_count = self.token_counter.count_string(compacted)

        return CompactorResult(compacted=compacted, token_count=token_count)
