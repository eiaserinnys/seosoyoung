"""ê´€ì°° ë¡œê·¸ ì €ì¥ì†Œ

íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜(thread_ts) ë‹¨ìœ„ ê´€ì°° ë¡œê·¸, ëŒ€í™” ë¡œê·¸, ì¥ê¸° ê¸°ì–µì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

ì €ì¥ êµ¬ì¡°:
    memory/
    â”œâ”€â”€ observations/
    â”‚   â”œâ”€â”€ {thread_ts}.json         # ì„¸ì…˜ë³„ ê´€ì°° ë¡œê·¸ (JSON í•­ëª© ë°°ì—´)
    â”‚   â”œâ”€â”€ {thread_ts}.meta.json   # ë©”íƒ€ë°ì´í„° (user_id í¬í•¨)
    â”‚   â””â”€â”€ {thread_ts}.inject      # OM ì£¼ì… í”Œë˜ê·¸ (ì¡´ì¬í•˜ë©´ ë‹¤ìŒ ìš”ì²­ì— ì£¼ì…)
    â”œâ”€â”€ pending/
    â”‚   â””â”€â”€ {thread_ts}.jsonl       # ì„¸ì…˜ë³„ ë¯¸ê´€ì°° ëŒ€í™” ë²„í¼ (ëˆ„ì )
    â”œâ”€â”€ conversations/
    â”‚   â””â”€â”€ {thread_ts}.jsonl       # ì„¸ì…˜ë³„ ëŒ€í™” ë¡œê·¸
    â”œâ”€â”€ candidates/
    â”‚   â””â”€â”€ {thread_ts}.jsonl       # ì¥ê¸° ê¸°ì–µ í›„ë³´ (ì„¸ì…˜ ë‹¨ìœ„ ëˆ„ì )
    â””â”€â”€ persistent/
        â”œâ”€â”€ recent.json              # í™œì„± ì¥ê¸° ê¸°ì–µ (JSON í•­ëª© ë°°ì—´)
        â”œâ”€â”€ recent.meta.json        # ë©”íƒ€ë°ì´í„°
        â””â”€â”€ archive/                # ì»´íŒ©ì…˜ ì‹œ ì´ì „ ë²„ì „ ë³´ì¡´
            â””â”€â”€ recent_{timestamp}.json
"""

import json
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime, timezone
from pathlib import Path

from filelock import FileLock

logger = logging.getLogger(__name__)


# â”€â”€ í•­ëª© ëª¨ë¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


@dataclass
class ObservationItem:
    """ì„¸ì…˜ ê´€ì°° í•­ëª©"""

    id: str  # "obs_{YYYYMMDD}_{seq:03d}"
    priority: str  # "ğŸ”´" | "ğŸŸ¡" | "ğŸŸ¢"
    content: str
    session_date: str  # "YYYY-MM-DD"
    created_at: str  # ISO 8601
    source: str = "observer"  # "observer" | "reflector" | "migrated"

    def to_dict(self) -> dict:
        return {
            "id": self.id,
            "priority": self.priority,
            "content": self.content,
            "session_date": self.session_date,
            "created_at": self.created_at,
            "source": self.source,
        }

    @classmethod
    def from_dict(cls, d: dict) -> "ObservationItem":
        return cls(
            id=d["id"],
            priority=d.get("priority", "ğŸŸ¢"),
            content=d.get("content", ""),
            session_date=d.get("session_date", ""),
            created_at=d.get("created_at", ""),
            source=d.get("source", "observer"),
        )


@dataclass
class PersistentItem:
    """ì¥ê¸° ê¸°ì–µ í•­ëª©"""

    id: str  # "ltm_{YYYYMMDD}_{seq:03d}"
    priority: str  # "ğŸ”´" | "ğŸŸ¡" | "ğŸŸ¢"
    content: str
    promoted_at: str  # ISO 8601
    source_obs_ids: list[str] = field(default_factory=list)

    def to_dict(self) -> dict:
        d = {
            "id": self.id,
            "priority": self.priority,
            "content": self.content,
            "promoted_at": self.promoted_at,
        }
        if self.source_obs_ids:
            d["source_obs_ids"] = self.source_obs_ids
        return d

    @classmethod
    def from_dict(cls, d: dict) -> "PersistentItem":
        return cls(
            id=d["id"],
            priority=d.get("priority", "ğŸŸ¢"),
            content=d.get("content", ""),
            promoted_at=d.get("promoted_at", ""),
            source_obs_ids=d.get("source_obs_ids", []),
        )


# â”€â”€ ID ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _next_seq(items: list[dict], prefix: str, date_str: str) -> int:
    """ê¸°ì¡´ í•­ëª©ì—ì„œ ê°™ì€ ë‚ ì§œì˜ ìµœëŒ€ ì‹œí€€ìŠ¤ ë²ˆí˜¸ + 1ì„ ë°˜í™˜."""
    date_part = date_str.replace("-", "")
    pattern = f"{prefix}_{date_part}_"
    max_seq = -1
    for item in items:
        item_id = item.get("id", "")
        if item_id.startswith(pattern):
            try:
                seq = int(item_id[len(pattern):])
                max_seq = max(max_seq, seq)
            except ValueError:
                pass
    return max_seq + 1


def generate_obs_id(existing_items: list[dict], date_str: str | None = None) -> str:
    """ê´€ì°° í•­ëª© IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if date_str is None:
        date_str = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    date_part = date_str.replace("-", "")
    seq = _next_seq(existing_items, "obs", date_str)
    return f"obs_{date_part}_{seq:03d}"


def generate_ltm_id(existing_items: list[dict], date_str: str | None = None) -> str:
    """ì¥ê¸° ê¸°ì–µ í•­ëª© IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if date_str is None:
        date_str = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    date_part = date_str.replace("-", "")
    seq = _next_seq(existing_items, "ltm", date_str)
    return f"ltm_{date_part}_{seq:03d}"


# â”€â”€ ë§ˆí¬ë‹¤ìš´ â†’ JSON ë§ˆì´ê·¸ë ˆì´ì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def parse_md_observations(md_text: str) -> list[dict]:
    """ë§ˆí¬ë‹¤ìš´ ê´€ì°° ë¡œê·¸ë¥¼ í•­ëª© ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.

    ## [YYYY-MM-DD] ... í—¤ë”ë¡œ ì„¸ì…˜ ë‚ ì§œë¥¼ ê²°ì •í•˜ê³ ,
    ì´ëª¨ì§€(ğŸ”´ğŸŸ¡ğŸŸ¢)ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì„ í•­ëª©ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    if not md_text or not md_text.strip():
        return []

    items: list[dict] = []
    current_date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    now_iso = datetime.now(timezone.utc).isoformat()

    for line in md_text.strip().splitlines():
        stripped = line.strip()
        if not stripped:
            continue

        date_match = re.match(r"^##\s*\[(\d{4}-\d{2}-\d{2})\]", stripped)
        if date_match:
            current_date = date_match.group(1)
            continue

        priority = None
        content = ""
        for emoji in ("ğŸ”´", "ğŸŸ¡", "ğŸŸ¢"):
            if stripped.startswith(emoji):
                priority = emoji
                content = stripped[len(emoji):].strip()
                content = re.sub(
                    r"^(HIGH|MEDIUM|LOW)\s*[-â€“â€”]?\s*", "", content
                ).strip()
                break

        if priority and content:
            item_id = generate_obs_id(items, current_date)
            items.append({
                "id": item_id,
                "priority": priority,
                "content": content,
                "session_date": current_date,
                "created_at": now_iso,
                "source": "migrated",
            })

    return items


def parse_md_persistent(md_text: str) -> list[dict]:
    """ë§ˆí¬ë‹¤ìš´ ì¥ê¸° ê¸°ì–µì„ í•­ëª© ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤."""
    if not md_text or not md_text.strip():
        return []

    items: list[dict] = []
    now_iso = datetime.now(timezone.utc).isoformat()

    for line in md_text.strip().splitlines():
        stripped = line.strip()
        if not stripped:
            continue

        priority = None
        content = ""
        for emoji in ("ğŸ”´", "ğŸŸ¡", "ğŸŸ¢"):
            if stripped.startswith(emoji):
                priority = emoji
                content = stripped[len(emoji):].strip()
                content = re.sub(
                    r"^(HIGH|MEDIUM|LOW)\s*[-â€“â€”]?\s*", "", content
                ).strip()
                break

        if not priority:
            if stripped.startswith("#") or stripped.startswith("---"):
                continue
            priority = "ğŸŸ¡"
            content = stripped

        if content:
            item_id = generate_ltm_id(items)
            items.append({
                "id": item_id,
                "priority": priority,
                "content": content,
                "promoted_at": now_iso,
            })

    return items


# â”€â”€ ë©”ëª¨ë¦¬ ë ˆì½”ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


@dataclass
class MemoryRecord:
    """ì„¸ì…˜ë³„ ê´€ì°° ë¡œê·¸ ë ˆì½”ë“œ

    thread_tsë¥¼ ê¸°ë³¸ í‚¤ë¡œ ì‚¬ìš©í•˜ê³ , user_idëŠ” ë©”íƒ€ë°ì´í„°ë¡œ ë³´ê´€í•©ë‹ˆë‹¤.
    """

    thread_ts: str
    user_id: str = ""
    username: str = ""
    observations: list[dict] = field(default_factory=list)
    observation_tokens: int = 0
    last_observed_at: datetime | None = None
    total_sessions_observed: int = 0
    reflection_count: int = 0
    anchor_ts: str = ""  # OM ë””ë²„ê·¸ ì±„ë„ ì•µì»¤ ë©”ì‹œì§€ ts (ì„¸ì…˜ ê°„ ìœ ì§€)
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

    def to_meta_dict(self) -> dict:
        """ë©”íƒ€ë°ì´í„°ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ dictë¡œ ë³€í™˜"""
        d = {
            "thread_ts": self.thread_ts,
            "user_id": self.user_id,
            "username": self.username,
            "observation_tokens": self.observation_tokens,
            "last_observed_at": (
                self.last_observed_at.isoformat() if self.last_observed_at else None
            ),
            "total_sessions_observed": self.total_sessions_observed,
            "reflection_count": self.reflection_count,
            "created_at": self.created_at.isoformat(),
        }
        if self.anchor_ts:
            d["anchor_ts"] = self.anchor_ts
        return d

    @classmethod
    def from_meta_dict(
        cls, data: dict, observations: list[dict] | None = None
    ) -> "MemoryRecord":
        """dictì—ì„œ MemoryRecordë¥¼ ë³µì›"""
        last_observed = data.get("last_observed_at")
        created = data.get("created_at")
        return cls(
            thread_ts=data.get("thread_ts", ""),
            user_id=data.get("user_id", ""),
            username=data.get("username", ""),
            observations=observations or [],
            observation_tokens=data.get("observation_tokens", 0),
            last_observed_at=(
                datetime.fromisoformat(last_observed) if last_observed else None
            ),
            total_sessions_observed=data.get("total_sessions_observed", 0),
            reflection_count=data.get("reflection_count", 0),
            anchor_ts=data.get("anchor_ts", ""),
            created_at=(
                datetime.fromisoformat(created)
                if created
                else datetime.now(timezone.utc)
            ),
        )


class MemoryStore:
    """íŒŒì¼ ê¸°ë°˜ ê´€ì°° ë¡œê·¸ ì €ì¥ì†Œ

    ì„¸ì…˜(thread_ts)ì„ ê¸°ë³¸ í‚¤ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """

    def __init__(self, base_dir: str | Path):
        self.base_dir = Path(base_dir)
        self.observations_dir = self.base_dir / "observations"
        self.pending_dir = self.base_dir / "pending"
        self.conversations_dir = self.base_dir / "conversations"
        self.candidates_dir = self.base_dir / "candidates"
        self.persistent_dir = self.base_dir / "persistent"

    def _ensure_dirs(self) -> None:
        """ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±"""
        self.observations_dir.mkdir(parents=True, exist_ok=True)
        self.pending_dir.mkdir(parents=True, exist_ok=True)
        self.conversations_dir.mkdir(parents=True, exist_ok=True)
        self.candidates_dir.mkdir(parents=True, exist_ok=True)
        self.persistent_dir.mkdir(parents=True, exist_ok=True)

    def _obs_path(self, thread_ts: str) -> Path:
        return self.observations_dir / f"{thread_ts}.json"

    def _obs_md_path(self, thread_ts: str) -> Path:
        """ë ˆê±°ì‹œ .md ê²½ë¡œ (ë§ˆì´ê·¸ë ˆì´ì…˜ìš©)"""
        return self.observations_dir / f"{thread_ts}.md"

    def _meta_path(self, thread_ts: str) -> Path:
        return self.observations_dir / f"{thread_ts}.meta.json"

    def _lock_path(self, thread_ts: str) -> Path:
        return self.observations_dir / f"{thread_ts}.lock"

    def _conv_path(self, thread_ts: str) -> Path:
        return self.conversations_dir / f"{thread_ts}.jsonl"

    def get_record(self, thread_ts: str) -> MemoryRecord | None:
        """ì„¸ì…˜ì˜ ê´€ì°° ë ˆì½”ë“œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ None."""
        meta_path = self._meta_path(thread_ts)
        if not meta_path.exists():
            return None

        lock = FileLock(str(self._lock_path(thread_ts)), timeout=5)
        with lock:
            meta_data = json.loads(meta_path.read_text(encoding="utf-8"))

            observations: list[dict] = []
            obs_path = self._obs_path(thread_ts)
            obs_md_path = self._obs_md_path(thread_ts)

            if obs_path.exists():
                observations = json.loads(obs_path.read_text(encoding="utf-8"))
            elif obs_md_path.exists():
                # ë ˆê±°ì‹œ .md â†’ .json ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜
                md_text = obs_md_path.read_text(encoding="utf-8")
                observations = parse_md_observations(md_text)
                obs_path.write_text(
                    json.dumps(observations, ensure_ascii=False, indent=2),
                    encoding="utf-8",
                )
                obs_md_path.unlink()
                logger.info(
                    f"ê´€ì°° ë¡œê·¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {thread_ts} (.md â†’ .json)"
                )

            return MemoryRecord.from_meta_dict(meta_data, observations)

    def save_record(self, record: MemoryRecord) -> None:
        """ê´€ì°° ë ˆì½”ë“œë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        self._ensure_dirs()

        lock = FileLock(str(self._lock_path(record.thread_ts)), timeout=5)
        with lock:
            # ê´€ì°° ë¡œê·¸ (JSON ë°°ì—´)
            self._obs_path(record.thread_ts).write_text(
                json.dumps(record.observations, ensure_ascii=False, indent=2),
                encoding="utf-8",
            )

            # ë©”íƒ€ë°ì´í„° (JSON)
            self._meta_path(record.thread_ts).write_text(
                json.dumps(record.to_meta_dict(), ensure_ascii=False, indent=2),
                encoding="utf-8",
            )

    def _pending_path(self, thread_ts: str) -> Path:
        return self.pending_dir / f"{thread_ts}.jsonl"

    def _pending_lock_path(self, thread_ts: str) -> Path:
        return self.pending_dir / f"{thread_ts}.lock"

    def append_pending_messages(self, thread_ts: str, messages: list[dict]) -> None:
        """ë¯¸ê´€ì°° ëŒ€í™”ë¥¼ ì„¸ì…˜ë³„ ë²„í¼ì— ëˆ„ì í•©ë‹ˆë‹¤."""
        self._ensure_dirs()

        lock = FileLock(str(self._pending_lock_path(thread_ts)), timeout=5)
        with lock:
            with open(self._pending_path(thread_ts), "a", encoding="utf-8") as f:
                for msg in messages:
                    f.write(json.dumps(msg, ensure_ascii=False) + "\n")

    def load_pending_messages(self, thread_ts: str) -> list[dict]:
        """ë¯¸ê´€ì°° ëŒ€í™” ë²„í¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸."""
        pending_path = self._pending_path(thread_ts)
        if not pending_path.exists():
            return []

        lock = FileLock(str(self._pending_lock_path(thread_ts)), timeout=5)
        with lock:
            messages = []
            with open(pending_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line:
                        messages.append(json.loads(line))
            return messages

    def clear_pending_messages(self, thread_ts: str) -> None:
        """ê´€ì°° ì™„ë£Œ í›„ ë¯¸ê´€ì°° ëŒ€í™” ë²„í¼ë¥¼ ë¹„ì›ë‹ˆë‹¤."""
        pending_path = self._pending_path(thread_ts)
        if pending_path.exists():
            lock = FileLock(str(self._pending_lock_path(thread_ts)), timeout=5)
            with lock:
                pending_path.unlink()

    def _new_obs_path(self, thread_ts: str) -> Path:
        return self.observations_dir / f"{thread_ts}.new.json"

    def _new_obs_md_path(self, thread_ts: str) -> Path:
        """ë ˆê±°ì‹œ .new.md ê²½ë¡œ (ë§ˆì´ê·¸ë ˆì´ì…˜ìš©)"""
        return self.observations_dir / f"{thread_ts}.new.md"

    def save_new_observations(self, thread_ts: str, content: list[dict]) -> None:
        """ì´ë²ˆ í„´ì—ì„œ ìƒˆë¡œ ì¶”ê°€ëœ ê´€ì°°ë§Œ ë³„ë„ ì €ì¥í•©ë‹ˆë‹¤."""
        self._ensure_dirs()
        self._new_obs_path(thread_ts).write_text(
            json.dumps(content, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )

    def get_new_observations(self, thread_ts: str) -> list[dict]:
        """ì €ì¥ëœ ìƒˆ ê´€ì°°ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸."""
        path = self._new_obs_path(thread_ts)
        if path.exists():
            return json.loads(path.read_text(encoding="utf-8"))
        # ë ˆê±°ì‹œ .md ë§ˆì´ê·¸ë ˆì´ì…˜
        md_path = self._new_obs_md_path(thread_ts)
        if md_path.exists():
            md_text = md_path.read_text(encoding="utf-8")
            items = parse_md_observations(md_text)
            md_path.unlink()
            return items
        return []

    def clear_new_observations(self, thread_ts: str) -> None:
        """ì£¼ì… ì™„ë£Œëœ ìƒˆ ê´€ì°°ì„ í´ë¦¬ì–´í•©ë‹ˆë‹¤."""
        path = self._new_obs_path(thread_ts)
        if path.exists():
            path.unlink()
        # ë ˆê±°ì‹œë„ ì •ë¦¬
        md_path = self._new_obs_md_path(thread_ts)
        if md_path.exists():
            md_path.unlink()

    def _inject_flag_path(self, thread_ts: str) -> Path:
        return self.observations_dir / f"{thread_ts}.inject"

    def set_inject_flag(self, thread_ts: str) -> None:
        """ë‹¤ìŒ ìš”ì²­ì— OMì„ ì£¼ì…í•˜ë„ë¡ í”Œë˜ê·¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        self._ensure_dirs()
        self._inject_flag_path(thread_ts).write_text("1", encoding="utf-8")

    def check_and_clear_inject_flag(self, thread_ts: str) -> bool:
        """inject í”Œë˜ê·¸ë¥¼ í™•ì¸í•˜ê³  ìˆìœ¼ë©´ ì œê±°í•©ë‹ˆë‹¤.

        Returns:
            True: í”Œë˜ê·¸ê°€ ìˆì—ˆìŒ (ì£¼ì… í•„ìš”), False: ì—†ì—ˆìŒ
        """
        flag_path = self._inject_flag_path(thread_ts)
        if flag_path.exists():
            flag_path.unlink()
            return True
        return False

    def save_conversation(self, thread_ts: str, messages: list[dict]) -> None:
        """ì„¸ì…˜ ëŒ€í™” ë¡œê·¸ë¥¼ JSONLë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        self._ensure_dirs()

        conv_path = self._conv_path(thread_ts)
        with open(conv_path, "w", encoding="utf-8") as f:
            for msg in messages:
                f.write(json.dumps(msg, ensure_ascii=False) + "\n")

    def load_conversation(self, thread_ts: str) -> list[dict] | None:
        """ì„¸ì…˜ ëŒ€í™” ë¡œê·¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ None."""
        conv_path = self._conv_path(thread_ts)
        if not conv_path.exists():
            return None

        messages = []
        with open(conv_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    messages.append(json.loads(line))
        return messages

    # â”€â”€ candidates (ì¥ê¸° ê¸°ì–µ í›„ë³´) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _candidates_path(self, thread_ts: str) -> Path:
        return self.candidates_dir / f"{thread_ts}.jsonl"

    def _candidates_lock_path(self, thread_ts: str) -> Path:
        return self.candidates_dir / f"{thread_ts}.lock"

    def append_candidates(self, thread_ts: str, entries: list[dict]) -> None:
        """í›„ë³´ í•­ëª©ì„ ì„¸ì…˜ë³„ íŒŒì¼ì— ëˆ„ì í•©ë‹ˆë‹¤."""
        self._ensure_dirs()

        lock = FileLock(str(self._candidates_lock_path(thread_ts)), timeout=5)
        with lock:
            with open(self._candidates_path(thread_ts), "a", encoding="utf-8") as f:
                for entry in entries:
                    f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    def load_candidates(self, thread_ts: str) -> list[dict]:
        """ì„¸ì…˜ë³„ í›„ë³´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸."""
        path = self._candidates_path(thread_ts)
        if not path.exists():
            return []

        lock = FileLock(str(self._candidates_lock_path(thread_ts)), timeout=5)
        with lock:
            entries = []
            with open(path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line:
                        entries.append(json.loads(line))
            return entries

    def load_all_candidates(self) -> list[dict]:
        """ì „ì²´ ì„¸ì…˜ì˜ í›„ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        if not self.candidates_dir.exists():
            return []

        all_entries = []
        for path in sorted(self.candidates_dir.glob("*.jsonl")):
            with open(path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line:
                        all_entries.append(json.loads(line))
        return all_entries

    def count_all_candidate_tokens(self) -> int:
        """ì „ì²´ í›„ë³´ì˜ content í•„ë“œ í† í° í•©ì‚°."""
        from seosoyoung.memory.token_counter import TokenCounter

        candidates = self.load_all_candidates()
        if not candidates:
            return 0

        counter = TokenCounter()
        total = 0
        for entry in candidates:
            total += counter.count_string(entry.get("content", ""))
        return total

    def clear_all_candidates(self) -> None:
        """ëª¨ë“  í›„ë³´ íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
        if not self.candidates_dir.exists():
            return

        for path in self.candidates_dir.glob("*.jsonl"):
            path.unlink()
        for path in self.candidates_dir.glob("*.lock"):
            path.unlink()

    # â”€â”€ persistent (ì¥ê¸° ê¸°ì–µ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _persistent_content_path(self) -> Path:
        return self.persistent_dir / "recent.json"

    def _persistent_md_path(self) -> Path:
        """ë ˆê±°ì‹œ .md ê²½ë¡œ (ë§ˆì´ê·¸ë ˆì´ì…˜ìš©)"""
        return self.persistent_dir / "recent.md"

    def _persistent_meta_path(self) -> Path:
        return self.persistent_dir / "recent.meta.json"

    def _persistent_lock_path(self) -> Path:
        return self.persistent_dir / "recent.lock"

    def _persistent_archive_dir(self) -> Path:
        return self.persistent_dir / "archive"

    def get_persistent(self) -> dict | None:
        """ì¥ê¸° ê¸°ì–µì„ ë¡œë“œí•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ None.

        Returns:
            {"content": list[dict], "meta": dict} ë˜ëŠ” None
        """
        content_path = self._persistent_content_path()
        md_path = self._persistent_md_path()

        if not content_path.exists() and not md_path.exists():
            return None

        lock = FileLock(str(self._persistent_lock_path()), timeout=5)
        with lock:
            content: list[dict] = []
            if content_path.exists():
                content = json.loads(content_path.read_text(encoding="utf-8"))
            elif md_path.exists():
                # ë ˆê±°ì‹œ .md â†’ .json ìë™ ë§ˆì´ê·¸ë ˆì´ì…˜
                md_text = md_path.read_text(encoding="utf-8")
                content = parse_md_persistent(md_text)
                content_path.write_text(
                    json.dumps(content, ensure_ascii=False, indent=2),
                    encoding="utf-8",
                )
                md_path.unlink()
                logger.info("ì¥ê¸° ê¸°ì–µ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ (.md â†’ .json)")

            meta = {}
            meta_path = self._persistent_meta_path()
            if meta_path.exists():
                meta = json.loads(meta_path.read_text(encoding="utf-8"))
            return {"content": content, "meta": meta}

    def save_persistent(self, content: list[dict], meta: dict) -> None:
        """ì¥ê¸° ê¸°ì–µì„ ì €ì¥í•©ë‹ˆë‹¤."""
        self._ensure_dirs()

        lock = FileLock(str(self._persistent_lock_path()), timeout=5)
        with lock:
            self._persistent_content_path().write_text(
                json.dumps(content, ensure_ascii=False, indent=2),
                encoding="utf-8",
            )
            self._persistent_meta_path().write_text(
                json.dumps(meta, ensure_ascii=False, indent=2),
                encoding="utf-8",
            )

    def archive_persistent(self) -> Path | None:
        """ê¸°ì¡´ ì¥ê¸° ê¸°ì–µì„ archive/ì— ë°±ì—…í•©ë‹ˆë‹¤.

        Returns:
            ì•„ì¹´ì´ë¸Œ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None (ì¥ê¸° ê¸°ì–µì´ ì—†ì„ ë•Œ)
        """
        content_path = self._persistent_content_path()
        if not content_path.exists():
            return None

        archive_dir = self._persistent_archive_dir()
        archive_dir.mkdir(parents=True, exist_ok=True)

        lock = FileLock(str(self._persistent_lock_path()), timeout=5)
        with lock:
            content = content_path.read_text(encoding="utf-8")
            timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S%f")
            archive_path = archive_dir / f"recent_{timestamp}.json"
            archive_path.write_text(content, encoding="utf-8")
            return archive_path
