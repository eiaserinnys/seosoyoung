"""Promoter / Compactor ëª¨ë“ˆ

ì¥ê¸° ê¸°ì–µ í›„ë³´ë¥¼ ê²€í† í•˜ì—¬ ìŠ¹ê²©(Promoter)í•˜ê³ ,
ì¥ê¸° ê¸°ì–µì´ ì„ê³„ì¹˜ë¥¼ ë„˜ìœ¼ë©´ ì••ì¶•(Compactor)í•©ë‹ˆë‹¤.
"""

import json
import logging
from dataclasses import dataclass, field
from datetime import datetime, timezone

import openai

from seosoyoung.slackbot.memory.prompts import build_compactor_prompt, build_promoter_prompt
from seosoyoung.slackbot.memory.store import generate_ltm_id
from seosoyoung.slackbot.memory.token_counter import TokenCounter

logger = logging.getLogger(__name__)


@dataclass
class PromoterResult:
    """Promoter ì¶œë ¥ ê²°ê³¼"""

    promoted: list[dict] = field(default_factory=list)
    rejected: list[dict] = field(default_factory=list)
    promoted_count: int = 0
    rejected_count: int = 0
    priority_counts: dict = None

    def __post_init__(self):
        if self.priority_counts is None:
            self.priority_counts = {}


@dataclass
class CompactorResult:
    """Compactor ì¶œë ¥ ê²°ê³¼"""

    compacted: list[dict] = field(default_factory=list)
    token_count: int = 0


def _extract_json(text: str) -> dict | list:
    """ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ JSONì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    text = text.strip()

    if "```json" in text:
        start = text.index("```json") + 7
        end = text.index("```", start)
        text = text[start:end].strip()
    elif "```" in text:
        start = text.index("```") + 3
        end = text.index("```", start)
        text = text[start:end].strip()

    # ë°°ì—´ ë˜ëŠ” ê°ì²´
    bracket_start = text.find("[")
    brace_start = text.find("{")

    if bracket_start >= 0 and (brace_start < 0 or bracket_start < brace_start):
        bracket_end = text.rfind("]")
        if bracket_end > bracket_start:
            return json.loads(text[bracket_start:bracket_end + 1])

    if brace_start >= 0:
        brace_end = text.rfind("}")
        if brace_end > brace_start:
            return json.loads(text[brace_start:brace_end + 1])

    return json.loads(text)


def _assign_ltm_ids(raw_items: list, existing: list[dict]) -> list[dict]:
    """LTM í•­ëª©ì— IDë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.

    ê¸°ì¡´ í•­ëª©ê³¼ content+priorityê°€ ì¼ì¹˜í•˜ë©´ ê¸°ì¡´ IDë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
    LLMì´ idë¥¼ ë°˜í™˜í•œ ê²½ìš° ê·¸ IDë¥¼ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    existing_map: dict[tuple, str] = {}
    for item in existing:
        key = (item.get("content", ""), item.get("priority", ""))
        existing_map[key] = item.get("id", "")

    result: list[dict] = []
    all_items = list(existing)
    now_iso = datetime.now(timezone.utc).isoformat()

    for raw in raw_items:
        if not isinstance(raw, dict) or not raw.get("content"):
            continue

        priority = raw.get("priority", "ğŸŸ¢")
        content = raw["content"]

        # ID ê²°ì •: LLMì´ ë°˜í™˜í•œ id > content+priority ë§¤ì¹­ > ì‹ ê·œ ìƒì„±
        item_id = raw.get("id")
        if not item_id:
            key = (content, priority)
            item_id = existing_map.get(key)
        if not item_id:
            item_id = generate_ltm_id(all_items)

        item = {
            "id": item_id,
            "priority": priority,
            "content": content,
            "promoted_at": raw.get("promoted_at", now_iso),
        }
        if raw.get("source_obs_ids"):
            item["source_obs_ids"] = raw["source_obs_ids"]

        result.append(item)
        all_items.append(item)

    return result


def parse_promoter_output(
    text: str, existing_items: list[dict] | None = None
) -> PromoterResult:
    """Promoter ì‘ë‹µ JSONì—ì„œ promotedì™€ rejectedë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    existing = existing_items or []

    try:
        data = _extract_json(text)
    except (json.JSONDecodeError, ValueError):
        logger.warning("Promoter ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨")
        return PromoterResult()

    if not isinstance(data, dict):
        return PromoterResult()

    # promoted
    raw_promoted = data.get("promoted", [])
    promoted = (
        _assign_ltm_ids(raw_promoted, existing) if isinstance(raw_promoted, list) else []
    )

    # rejected
    raw_rejected = data.get("rejected", [])
    rejected = raw_rejected if isinstance(raw_rejected, list) else []

    # ìš°ì„ ìˆœìœ„ ì¹´ìš´íŠ¸
    priority_counts: dict[str, int] = {}
    for item in promoted:
        p = item.get("priority", "ğŸŸ¢")
        priority_counts[p] = priority_counts.get(p, 0) + 1

    return PromoterResult(
        promoted=promoted,
        rejected=rejected,
        promoted_count=len(promoted),
        rejected_count=len(rejected),
        priority_counts=priority_counts,
    )


def parse_compactor_output(
    text: str, existing_items: list[dict] | None = None
) -> list[dict]:
    """Compactor ì‘ë‹µì—ì„œ JSON ë°°ì—´ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
    existing = existing_items or []

    try:
        data = _extract_json(text)
    except (json.JSONDecodeError, ValueError):
        logger.warning("Compactor ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨")
        return existing  # fallback: ê¸°ì¡´ í•­ëª© ìœ ì§€

    if isinstance(data, list):
        raw_items = data
    elif isinstance(data, dict):
        raw_items = data.get("compacted", data.get("items", []))
    else:
        return existing

    return _assign_ltm_ids(raw_items, existing)


class Promoter:
    """ì¥ê¸° ê¸°ì–µ í›„ë³´ë¥¼ ê²€í† í•˜ì—¬ ìŠ¹ê²©"""

    def __init__(self, api_key: str, model: str = "gpt-5.2"):
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.model = model

    async def promote(
        self,
        candidates: list[dict],
        existing_persistent: list[dict],
    ) -> PromoterResult:
        """í›„ë³´ í•­ëª©ë“¤ì„ ê²€í† í•˜ì—¬ ì¥ê¸° ê¸°ì–µ ìŠ¹ê²© ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            candidates: í›„ë³´ í•­ëª© ë¦¬ìŠ¤íŠ¸ [{"ts": ..., "priority": ..., "content": ...}]
            existing_persistent: ê¸°ì¡´ ì¥ê¸° ê¸°ì–µ í•­ëª© ë¦¬ìŠ¤íŠ¸

        Returns:
            PromoterResult
        """
        prompt = build_promoter_prompt(existing_persistent, candidates)

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            max_completion_tokens=8_000,
        )

        result_text = response.choices[0].message.content or ""
        return parse_promoter_output(result_text, existing_persistent)

    @staticmethod
    def merge_promoted(existing: list[dict], promoted: list[dict]) -> list[dict]:
        """ìŠ¹ê²©ëœ í•­ëª©ì„ ê¸°ì¡´ ì¥ê¸° ê¸°ì–µì— ë¨¸ì§€í•©ë‹ˆë‹¤. ID ê¸°ë°˜ ì¤‘ë³µ ì œê±°."""
        merged = list(existing)
        existing_ids = {item.get("id") for item in existing if item.get("id")}

        for item in promoted:
            item_id = item.get("id")
            if item_id and item_id in existing_ids:
                # ê¸°ì¡´ í•­ëª© ì—…ë°ì´íŠ¸
                for i, ex in enumerate(merged):
                    if ex.get("id") == item_id:
                        merged[i] = item
                        break
            else:
                merged.append(item)

        return merged


class Compactor:
    """ì¥ê¸° ê¸°ì–µì„ ì••ì¶•"""

    def __init__(self, api_key: str, model: str = "gpt-5.2"):
        self.client = openai.AsyncOpenAI(api_key=api_key)
        self.model = model
        self.token_counter = TokenCounter()

    async def compact(
        self,
        persistent: list[dict],
        target_tokens: int,
    ) -> CompactorResult:
        """ì¥ê¸° ê¸°ì–µì„ ì••ì¶•í•©ë‹ˆë‹¤.

        Args:
            persistent: í˜„ì¬ ì¥ê¸° ê¸°ì–µ í•­ëª© ë¦¬ìŠ¤íŠ¸
            target_tokens: ëª©í‘œ í† í° ìˆ˜

        Returns:
            CompactorResult
        """
        prompt = build_compactor_prompt(persistent, target_tokens)

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            max_completion_tokens=16_000,
        )

        result_text = response.choices[0].message.content or ""
        compacted = parse_compactor_output(result_text, persistent)
        token_count = self.token_counter.count_string(
            json.dumps(compacted, ensure_ascii=False)
        )

        return CompactorResult(compacted=compacted, token_count=token_count)
